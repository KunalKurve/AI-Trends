{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using user defined functions in Spark\n",
    "\n",
    "- You've seen some of the power behind Spark's built-in string functions when it comes to manipulating DataFrames. However, once you reach a certain point, it becomes difficult to process the data in a without creating a rat's nest of function calls. Here's one place where you can use User Defined Functions to manipulate our DataFrames.\n",
    "\n",
    "- For this exercise, we'll use our `voter_df` DataFrame, but you're going to replace the `first_name` column with the first and middle names.\n",
    "\n",
    "- The `pyspark.sql.functions` library is available under the alias `F`. The classes from `pyspark.sql.types` are already imported.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Edit the `getFirstAndMiddle()` function to return a space separated string of names, except the last entry in the names list.\n",
    "- Define the function as a user-defined function. It should return a string type.\n",
    "- Create a new column on `voter_df` called `first_and_middle_name` using your UDF.\n",
    "- Show the Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# NOTE: Whichever package you want mention here.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell' \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# On yarn:\n",
    "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
    "# specify .master(\"yarn\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------------+\n",
      "|      DATE|        TITLE|         VOTER_NAME|\n",
      "+----------+-------------+-------------------+\n",
      "|02/08/2017|Councilmember|  Jennifer S. Gates|\n",
      "|02/08/2017|Councilmember| Philip T. Kingston|\n",
      "|02/08/2017|        Mayor|Michael S. Rawlings|\n",
      "|02/08/2017|Councilmember|       Adam Medrano|\n",
      "|02/08/2017|Councilmember|       Casey Thomas|\n",
      "|02/08/2017|Councilmember|Carolyn King Arnold|\n",
      "|02/08/2017|Councilmember|       Scott Griggs|\n",
      "|02/08/2017|Councilmember|   B. Adam  McGough|\n",
      "|02/08/2017|Councilmember|       Lee Kleinman|\n",
      "|02/08/2017|Councilmember|      Sandy Greyson|\n",
      "|02/08/2017|Councilmember|  Jennifer S. Gates|\n",
      "|02/08/2017|Councilmember| Philip T. Kingston|\n",
      "|02/08/2017|        Mayor|Michael S. Rawlings|\n",
      "|02/08/2017|Councilmember|       Adam Medrano|\n",
      "|02/08/2017|Councilmember|       Casey Thomas|\n",
      "|02/08/2017|Councilmember|Carolyn King Arnold|\n",
      "|02/08/2017|Councilmember| Rickey D. Callahan|\n",
      "|01/11/2017|Councilmember|  Jennifer S. Gates|\n",
      "|04/25/2018|Councilmember|     Sandy  Greyson|\n",
      "|04/25/2018|Councilmember| Jennifer S.  Gates|\n",
      "+----------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Load the CSV file\n",
    "voter_df = spark.read.format('csv').options(Header=True).load('file:///home/talentum/test-jupyter/P2/M1/SM16/Dataset/DallasCouncilVoters.csv')\n",
    "#voter_df.show()\n",
    "# Add a new column called splits separated on whitespace\n",
    "voter_df = voter_df.withColumn('splits', F.split(voter_df.VOTER_NAME, '\\s+'))\n",
    "\n",
    "# Create a new column called first_name based on the first item in splits\n",
    "voter_df = voter_df.withColumn('first_name', voter_df.splits.getItem(0))\n",
    "\n",
    "# Get the last entry of the splits list and create a column called last_name\n",
    "voter_df = voter_df.withColumn('last_name', voter_df.splits.getItem(F.size('splits') - 1))\n",
    "\n",
    "def getFirstAndMiddle(names):\n",
    "    # Assuming the first name is always at index 0\n",
    "    first_name = names[0]\n",
    "    # If there are more than 2 names, concatenate the second name as middle name\n",
    "    if len(names) > 2:\n",
    "        middle_name = ' '.join(names[1:-1])\n",
    "        return f\"{first_name} {middle_name}\"\n",
    "    else:\n",
    "        return first_name\n",
    "\n",
    "# Register the UDF\n",
    "udfFirstAndMiddle = F.udf(getFirstAndMiddle, StringType())\n",
    "\n",
    "# Create a new column using your UDF\n",
    "voter_df = voter_df.withColumn('first_and_middle_name', udfFirstAndMiddle(F.col('splits')))\n",
    "\n",
    "# Show the DataFrame\n",
    "voter_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------------+-----------------------+----------+---------+---------------------+\n",
      "|DATE      |TITLE        |VOTER_NAME         |splits                 |first_name|last_name|first_and_middle_name|\n",
      "+----------+-------------+-------------------+-----------------------+----------+---------+---------------------+\n",
      "|02/08/2017|Councilmember|Jennifer S. Gates  |[Jennifer, S., Gates]  |Jennifer  |Gates    |Jennifer S.          |\n",
      "|02/08/2017|Councilmember|Philip T. Kingston |[Philip, T., Kingston] |Philip    |Kingston |Philip T.            |\n",
      "|02/08/2017|Mayor        |Michael S. Rawlings|[Michael, S., Rawlings]|Michael   |Rawlings |Michael S.           |\n",
      "|02/08/2017|Councilmember|Adam Medrano       |[Adam, Medrano]        |Adam      |Medrano  |Adam                 |\n",
      "|02/08/2017|Councilmember|Casey Thomas       |[Casey, Thomas]        |Casey     |Thomas   |Casey                |\n",
      "|02/08/2017|Councilmember|Carolyn King Arnold|[Carolyn, King, Arnold]|Carolyn   |Arnold   |Carolyn King         |\n",
      "|02/08/2017|Councilmember|Scott Griggs       |[Scott, Griggs]        |Scott     |Griggs   |Scott                |\n",
      "|02/08/2017|Councilmember|B. Adam  McGough   |[B., Adam, McGough]    |B.        |McGough  |B. Adam              |\n",
      "|02/08/2017|Councilmember|Lee Kleinman       |[Lee, Kleinman]        |Lee       |Kleinman |Lee                  |\n",
      "|02/08/2017|Councilmember|Sandy Greyson      |[Sandy, Greyson]       |Sandy     |Greyson  |Sandy                |\n",
      "|02/08/2017|Councilmember|Jennifer S. Gates  |[Jennifer, S., Gates]  |Jennifer  |Gates    |Jennifer S.          |\n",
      "|02/08/2017|Councilmember|Philip T. Kingston |[Philip, T., Kingston] |Philip    |Kingston |Philip T.            |\n",
      "|02/08/2017|Mayor        |Michael S. Rawlings|[Michael, S., Rawlings]|Michael   |Rawlings |Michael S.           |\n",
      "|02/08/2017|Councilmember|Adam Medrano       |[Adam, Medrano]        |Adam      |Medrano  |Adam                 |\n",
      "|02/08/2017|Councilmember|Casey Thomas       |[Casey, Thomas]        |Casey     |Thomas   |Casey                |\n",
      "|02/08/2017|Councilmember|Carolyn King Arnold|[Carolyn, King, Arnold]|Carolyn   |Arnold   |Carolyn King         |\n",
      "|02/08/2017|Councilmember|Rickey D. Callahan |[Rickey, D., Callahan] |Rickey    |Callahan |Rickey D.            |\n",
      "|01/11/2017|Councilmember|Jennifer S. Gates  |[Jennifer, S., Gates]  |Jennifer  |Gates    |Jennifer S.          |\n",
      "|04/25/2018|Councilmember|Sandy  Greyson     |[Sandy, Greyson]       |Sandy     |Greyson  |Sandy                |\n",
      "|04/25/2018|Councilmember|Jennifer S.  Gates |[Jennifer, S., Gates]  |Jennifer  |Gates    |Jennifer S.          |\n",
      "+----------+-------------+-------------------+-----------------------+----------+---------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Load the CSV file\n",
    "voter_df = spark.read.format('csv').options(header=True).load('file:///home/talentum/test-jupyter/P2/M1/SM16/Dataset/DallasCouncilVoters.csv')\n",
    "\n",
    "voter_df = voter_df.filter(voter_df['VOTER_NAME'].isNotNull())\n",
    "\n",
    "# Add a new column called splits separated on whitespace\n",
    "voter_df = voter_df.withColumn('splits', F.split(voter_df.VOTER_NAME, '\\s+'))\n",
    "\n",
    "# Create a new column called first_name based on the first item in splits\n",
    "voter_df = voter_df.withColumn('first_name', voter_df.splits.getItem(0))\n",
    "\n",
    "# Get the last entry of the splits list and create a column called last_name\n",
    "voter_df = voter_df.withColumn('last_name', voter_df.splits.getItem(F.size(voter_df.splits) - 1))\n",
    "\n",
    "# Define a UDF to concatenate first and middle names\n",
    "def getFirstAndMiddle(names):\n",
    "    if names is None:\n",
    "        return None\n",
    "    # Assuming the first name is always at index 0\n",
    "    first_name = names[0]\n",
    "    # If there are more than 1 names, concatenate all names except the first and last to form the middle name(s)\n",
    "    if len(names) > 2:\n",
    "        middle_name = ' '.join(names[1:-1])\n",
    "        return f\"{first_name} {middle_name}\"\n",
    "    else:\n",
    "        return first_name\n",
    "    \n",
    "\n",
    "\n",
    "# Register the UDF with correct return type\n",
    "udfFirstAndMiddle = F.udf(getFirstAndMiddle, StringType())\n",
    "\n",
    "# Create a new column using your UDF\n",
    "voter_df = voter_df.withColumn('first_and_middle_name', udfFirstAndMiddle(F.col('splits')))\n",
    "\n",
    "# Show the DataFrame\n",
    "voter_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string sagar'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join(lst):\n",
    "    return ' '.join(lst[:-1])\n",
    "join(['string','sagar', 'Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------------+-----------------------+----------+---------+---------------------+\n",
      "|DATE      |TITLE        |VOTER_NAME         |splits                 |first_name|last_name|first_and_middle_name|\n",
      "+----------+-------------+-------------------+-----------------------+----------+---------+---------------------+\n",
      "|02/08/2017|Councilmember|Jennifer S. Gates  |[Jennifer, S., Gates]  |Jennifer  |Gates    |Jennifer S.          |\n",
      "|02/08/2017|Councilmember|Philip T. Kingston |[Philip, T., Kingston] |Philip    |Kingston |Philip T.            |\n",
      "|02/08/2017|Mayor        |Michael S. Rawlings|[Michael, S., Rawlings]|Michael   |Rawlings |Michael S.           |\n",
      "|02/08/2017|Councilmember|Adam Medrano       |[Adam, Medrano]        |Adam      |Medrano  |Adam                 |\n",
      "|02/08/2017|Councilmember|Casey Thomas       |[Casey, Thomas]        |Casey     |Thomas   |Casey                |\n",
      "|02/08/2017|Councilmember|Carolyn King Arnold|[Carolyn, King, Arnold]|Carolyn   |Arnold   |Carolyn King         |\n",
      "|02/08/2017|Councilmember|Scott Griggs       |[Scott, Griggs]        |Scott     |Griggs   |Scott                |\n",
      "|02/08/2017|Councilmember|B. Adam  McGough   |[B., Adam, McGough]    |B.        |McGough  |B. Adam              |\n",
      "|02/08/2017|Councilmember|Lee Kleinman       |[Lee, Kleinman]        |Lee       |Kleinman |Lee                  |\n",
      "|02/08/2017|Councilmember|Sandy Greyson      |[Sandy, Greyson]       |Sandy     |Greyson  |Sandy                |\n",
      "|02/08/2017|Councilmember|Jennifer S. Gates  |[Jennifer, S., Gates]  |Jennifer  |Gates    |Jennifer S.          |\n",
      "|02/08/2017|Councilmember|Philip T. Kingston |[Philip, T., Kingston] |Philip    |Kingston |Philip T.            |\n",
      "|02/08/2017|Mayor        |Michael S. Rawlings|[Michael, S., Rawlings]|Michael   |Rawlings |Michael S.           |\n",
      "|02/08/2017|Councilmember|Adam Medrano       |[Adam, Medrano]        |Adam      |Medrano  |Adam                 |\n",
      "|02/08/2017|Councilmember|Casey Thomas       |[Casey, Thomas]        |Casey     |Thomas   |Casey                |\n",
      "|02/08/2017|Councilmember|Carolyn King Arnold|[Carolyn, King, Arnold]|Carolyn   |Arnold   |Carolyn King         |\n",
      "|02/08/2017|Councilmember|Rickey D. Callahan |[Rickey, D., Callahan] |Rickey    |Callahan |Rickey D.            |\n",
      "|01/11/2017|Councilmember|Jennifer S. Gates  |[Jennifer, S., Gates]  |Jennifer  |Gates    |Jennifer S.          |\n",
      "|04/25/2018|Councilmember|Sandy  Greyson     |[Sandy, Greyson]       |Sandy     |Greyson  |Sandy                |\n",
      "|04/25/2018|Councilmember|Jennifer S.  Gates |[Jennifer, S., Gates]  |Jennifer  |Gates    |Jennifer S.          |\n",
      "+----------+-------------+-------------------+-----------------------+----------+---------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Load the CSV file\n",
    "voter_df = spark.read.format('csv').options(header=True).load('file:///home/talentum/test-jupyter/P2/M1/SM16/Dataset/DallasCouncilVoters.csv')\n",
    "\n",
    "# Add a new column called splits separated on whitespace\n",
    "voter_df = voter_df.withColumn('splits', F.split(voter_df.VOTER_NAME, '\\s+'))\n",
    "\n",
    "# Create a new column called first_name based on the first item in splits\n",
    "voter_df = voter_df.withColumn('first_name', voter_df.splits.getItem(0))\n",
    "\n",
    "# Get the last entry of the splits list and create a column called last_name\n",
    "voter_df = voter_df.withColumn('last_name', voter_df.splits.getItem(F.size(voter_df.splits) - 1))\n",
    "\n",
    "# Define a UDF to concatenate first and middle names\n",
    "def getFirstAndMiddle(names):\n",
    "    if names is None:\n",
    "        return None\n",
    "    # Assuming the first name is always at index 0\n",
    "    first_name = names[0]\n",
    "    # If there are more than 1 names, concatenate all names except the first and last to form the middle name(s)\n",
    "    if len(names) > 2:\n",
    "        middle_name = ' '.join(names[1:-1])\n",
    "        return f\"{first_name} {middle_name}\"\n",
    "    else:\n",
    "        return first_name\n",
    "    \n",
    "\n",
    "\n",
    "# Register the UDF with correct return type\n",
    "udfFirstAndMiddle = F.udf(getFirstAndMiddle, StringType())\n",
    "\n",
    "# Create a new column using your UDF\n",
    "voter_df = voter_df.withColumn('first_and_middle_name', udfFirstAndMiddle(F.col('splits')))\n",
    "\n",
    "# Show the DataFrame\n",
    "voter_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44122"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voter_df.filter(voter_df['VOTER_NAME'].isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voter_df.filter(voter_df['VOTER_NAME'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44625"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voter_df = spark.read.format('csv').options(header=True).load('file:///home/talentum/test-jupyter/P2/M1/SM16/Dataset/DallasCouncilVoters.csv')\n",
    "voter_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.127170868347339"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(503/44625)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------+-----------+---------+\n",
      "|splits                 |first_name|second_name|last_name|\n",
      "+-----------------------+----------+-----------+---------+\n",
      "|[Jennifer, S., Gates]  |Jennifer  |S.         |Gates    |\n",
      "|[Philip, T., Kingston] |Philip    |T.         |Kingston |\n",
      "|[Michael, S., Rawlings]|Michael   |S.         |Rawlings |\n",
      "|[Adam, Medrano]        |Adam      |null       |Medrano  |\n",
      "|[Casey, Thomas]        |Casey     |null       |Thomas   |\n",
      "|[Carolyn, King, Arnold]|Carolyn   |King       |Arnold   |\n",
      "|[Scott, Griggs]        |Scott     |null       |Griggs   |\n",
      "|[B., Adam, McGough]    |B.        |Adam       |McGough  |\n",
      "|[Lee, Kleinman]        |Lee       |null       |Kleinman |\n",
      "|[Sandy, Greyson]       |Sandy     |null       |Greyson  |\n",
      "|[Jennifer, S., Gates]  |Jennifer  |S.         |Gates    |\n",
      "|[Philip, T., Kingston] |Philip    |T.         |Kingston |\n",
      "|[Michael, S., Rawlings]|Michael   |S.         |Rawlings |\n",
      "|[Adam, Medrano]        |Adam      |null       |Medrano  |\n",
      "|[Casey, Thomas]        |Casey     |null       |Thomas   |\n",
      "|[Carolyn, King, Arnold]|Carolyn   |King       |Arnold   |\n",
      "|[Rickey, D., Callahan] |Rickey    |D.         |Callahan |\n",
      "|[Jennifer, S., Gates]  |Jennifer  |S.         |Gates    |\n",
      "|[Sandy, Greyson]       |Sandy     |null       |Greyson  |\n",
      "|[Jennifer, S., Gates]  |Jennifer  |S.         |Gates    |\n",
      "+-----------------------+----------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a new column called splits separated on whitespace\n",
    "voter_df = voter_df.withColumn('splits', F.split(voter_df.VOTER_NAME, '\\s+'))\n",
    "\n",
    "# Define UDFs to extract first name, second name, and last name\n",
    "def getFirstName(names):\n",
    "    if names is None:\n",
    "        return None\n",
    "    return names[0]\n",
    "\n",
    "def getSecondName(names):\n",
    "    if names is None:\n",
    "        return None\n",
    "    if len(names) > 2:\n",
    "        return names[1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getLastName(names):\n",
    "    if names is None:\n",
    "        return None\n",
    "    return names[-1]\n",
    "\n",
    "# Register the UDFs with correct return type\n",
    "udfFirstName = F.udf(getFirstName, StringType())\n",
    "udfSecondName = F.udf(getSecondName, StringType())\n",
    "udfLastName = F.udf(getLastName, StringType())\n",
    "\n",
    "# Create new columns using the UDFs\n",
    "voter_df = voter_df.withColumn('first_name', udfFirstName(F.col('splits')))\n",
    "voter_df = voter_df.withColumn('second_name', udfSecondName(F.col('splits')))\n",
    "voter_df = voter_df.withColumn('last_name', udfLastName(F.col('splits')))\n",
    "\n",
    "voter_df = voter_df.drop('DATE', 'TITLE', 'VOTER_NAME')\n",
    "\n",
    "voter_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
